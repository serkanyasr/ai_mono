services:
  # PostgreSQL Databases
  memory_postgres:
    image: pgvector/pgvector:pg17
    container_name: memory_db
    environment:
      POSTGRES_DB: ${MEMORY_DB_NAME:-memory_db}
      POSTGRES_USER: ${MEMORY_DB_USER:-postgres}
      POSTGRES_PASSWORD: ${MEMORY_DB_PASSWORD:-postgres}
    ports:
      - "${MEMORY_DB_PORT:-5432}:5432"
    volumes:
      - memory_data:/var/lib/postgresql/data
    restart: unless-stopped
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U ${MEMORY_DB_USER:-postgres} -d ${MEMORY_DB_NAME:-memory_db}"]
      interval: 5s
      timeout: 5s
      retries: 10
      start_period: 10s

  rag_postgres:
    image: pgvector/pgvector:pg17
    container_name: rag_db
    environment:
      POSTGRES_DB: ${RAG_DB_NAME:-rag_db}
      POSTGRES_USER: ${RAG_DB_USER:-postgres}
      POSTGRES_PASSWORD: ${RAG_DB_PASSWORD:-postgres}
    ports:
      - "${RAG_DB_PORT:-5433}:5432"
    volumes:
      - rag_data:/var/lib/postgresql/data
      - ./src/sql/schema.sql:/docker-entrypoint-initdb.d/schema.sql
    restart: unless-stopped
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U ${RAG_DB_USER:-postgres} -d ${RAG_DB_NAME:-rag_db}"]
      interval: 5s
      timeout: 5s
      retries: 10
      start_period: 10s

  # MCP Memory Server
  mcp_memory:
    build: .
    container_name: mcp_memory
    command: python -m src.mcp.memory.memory_server
    environment:
      - MEMORY_DB_HOST=memory_postgres
      - MEMORY_DB_PORT=5432
      - MEMORY_DB_NAME=${MEMORY_DB_NAME:-memory_db}
      - MEMORY_DB_USER=${MEMORY_DB_USER:-postgres}
      - MEMORY_DB_PASSWORD=${MEMORY_DB_PASSWORD:-postgres}
      - OPENAI_API_KEY=${OPENAI_API_KEY}
      - OPENAI_BASE_URL=${OPENAI_BASE_URL}
      - OPENAI_MODEL=${OPENAI_MODEL:-gpt-4o-mini}
      - OPENAI_EMBEDDING_MODEL=${OPENAI_EMBEDDING_MODEL:-text-embedding-3-small}
      - MEMORY_LLM_PROVIDER=${MEMORY_LLM_PROVIDER:-openai}
      - MEMORY_LLM_MODEL=${MEMORY_LLM_MODEL:-gpt-4o-mini}
      - MEMORY_EMBEDDING_PROVIDER=${MEMORY_EMBEDDING_PROVIDER:-openai}
      - MEMORY_EMBEDDING_MODEL=${MEMORY_EMBEDDING_MODEL:-text-embedding-3-small}
      - MEMORY_EMBEDDING_DIMS=${MEMORY_EMBEDDING_DIMS:-1536}
      - MEMORY_MCP_HOST=${MEMORY_MCP_HOST:-0.0.0.0}
      - MEMORY_MCP_PORT=${MEMORY_MCP_PORT:-8050}
      - MEMORY_MCP_TRANSPORT=${MEMORY_MCP_TRANSPORT:-streamable-http}
    ports:
      - "${MEMORY_MCP_PORT:-8050}:${MEMORY_MCP_PORT:-8050}"
    depends_on:
      memory_postgres:
        condition: service_healthy
    restart: unless-stopped

  # MCP RAG Server
  mcp_rag:
    build: .
    container_name: mcp_rag
    command: python -m src.mcp.rag.rag_server
    environment:
      - RAG_DB_HOST=rag_postgres
      - RAG_DB_PORT=5432
      - RAG_DB_NAME=${RAG_DB_NAME:-rag_db}
      - RAG_DB_USER=${RAG_DB_USER:-postgres}
      - RAG_DB_PASSWORD=${RAG_DB_PASSWORD:-postgres}
      - OPENAI_API_KEY=${OPENAI_API_KEY}
      - OPENAI_BASE_URL=${OPENAI_BASE_URL}
      - OPENAI_MODEL=${OPENAI_MODEL:-gpt-4o-mini}
      - OPENAI_EMBEDDING_MODEL=${OPENAI_EMBEDDING_MODEL:-text-embedding-3-small}
      - RAG_MCP_HOST=${RAG_MCP_HOST:-0.0.0.0}
      - RAG_MCP_PORT=${RAG_MCP_PORT:-8055}
      - RAG_MCP_TRANSPORT=${RAG_MCP_TRANSPORT:-streamable-http}
    ports:
      - "${RAG_MCP_PORT:-8055}:${RAG_MCP_PORT:-8055}"
    depends_on:
      rag_postgres:
        condition: service_healthy
    restart: unless-stopped

  # Main API Application
  api:
    build: .
    container_name: api
    command: python -m src.api.main
    environment:
      - MEMORY_DB_HOST=memory_postgres
      - MEMORY_DB_PORT=5432
      - MEMORY_DB_NAME=${MEMORY_DB_NAME:-memory_db}
      - MEMORY_DB_USER=${MEMORY_DB_USER:-postgres}
      - MEMORY_DB_PASSWORD=${MEMORY_DB_PASSWORD:-postgres}
      - RAG_DB_HOST=rag_postgres
      - RAG_DB_PORT=5432
      - RAG_DB_NAME=${RAG_DB_NAME:-rag_db}
      - RAG_DB_USER=${RAG_DB_USER:-postgres}
      - RAG_DB_PASSWORD=${RAG_DB_PASSWORD:-postgres}
      - OPENAI_API_KEY=${OPENAI_API_KEY}
      - OPENAI_BASE_URL=${OPENAI_BASE_URL}
      - OPENAI_MODEL=${OPENAI_MODEL:-gpt-4o-mini}
      - OPENAI_EMBEDDING_MODEL=${OPENAI_EMBEDDING_MODEL:-text-embedding-3-small}
      - OLLAMA_BASE_URL=${OLLAMA_BASE_URL:-http://localhost:11434}
      - OLLAMA_MODEL=${OLLAMA_MODEL:-llama3}
      - MEMORY_LLM_PROVIDER=${MEMORY_LLM_PROVIDER:-openai}
      - MEMORY_LLM_MODEL=${MEMORY_LLM_MODEL:-gpt-4o-mini}
      - MEMORY_EMBEDDING_PROVIDER=${MEMORY_EMBEDDING_PROVIDER:-openai}
      - MEMORY_EMBEDDING_MODEL=${MEMORY_EMBEDDING_MODEL:-text-embedding-3-small}
      - MEMORY_EMBEDDING_DIMS=${MEMORY_EMBEDDING_DIMS:-1536}
      - API_ENV=${API_ENV:-development}
      - API_HOST=0.0.0.0
      - API_PORT=${API_PORT:-8000}
      - API_LOG_LEVEL=${API_LOG_LEVEL:-info}
      - SECRET_KEY=${SECRET_KEY}
      - AGENT_CACHE_MAX_SIZE=${AGENT_CACHE_MAX_SIZE:-1000}
      - AGENT_CACHE_TTL_SECONDS=${AGENT_CACHE_TTL_SECONDS:-3600}
      - REDIS_URL=${REDIS_URL:-redis://localhost:6379/0}
      - MCP_MEMORY_URL=http://mcp_memory:${MEMORY_MCP_PORT:-8050}/mcp
      - MCP_RAG_URL=http://mcp_rag:${RAG_MCP_PORT:-8055}/mcp
    ports:
      - "${API_PORT:-8000}:${API_PORT:-8000}"

    deploy:
        resources:
          reservations:
            devices:
              - capabilities: [gpu]
    depends_on:
      memory_postgres:
        condition: service_healthy
      rag_postgres:
        condition: service_healthy
      mcp_memory:
        condition: service_started
      mcp_rag:
        condition: service_started
    restart: unless-stopped

  # Chainlit UI
  ui:
    build: .
    container_name: ui
    command: chainlit run src/ui/chainlit_app.py --host 0.0.0.0 --port 8502 --no-cache
    environment:
      - API_URL=http://api:${API_PORT:-8000}
      - CHAINLIT_AUTH_SECRET=${CHAINLIT_AUTH_SECRET}
      - CHAINLIT_DISABLE_CONFIG=true
    ports:
      - "8502:8502"
    depends_on:
      - api
    restart: unless-stopped

volumes:
  memory_data:
  rag_data:
